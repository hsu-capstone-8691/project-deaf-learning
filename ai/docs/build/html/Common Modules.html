

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Common Modules &mdash; KoSpeech latest documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Checkpoint" href="Checkpoint.html" />
    <link rel="prev" title="Speech Transformer" href="Speech Transformer.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> KoSpeech
          

          
          </a>

          
            
            
              <div class="version">
                latest
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">GETTING STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/intro.html">Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/Preparation.html">Preparation before Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/opts.html">Options</a></li>
</ul>
<p class="caption"><span class="caption-text">ARCHITECTURE</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Deep Speech 2.html">Deep Speech 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="Listen, Attend and Spell.html">Listen, Attend and Spell</a></li>
<li class="toctree-l1"><a class="reference internal" href="Speech Transformer.html">Speech Transformer</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Common Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-kospeech.models.attention">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-kospeech.models.extractor">Extractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-kospeech.models.modules">Modules</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">LIBRARY REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Checkpoint.html">Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="Data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Decode.html">Decode</a></li>
<li class="toctree-l1"><a class="reference internal" href="Evaluator.html">Evaluator</a></li>
<li class="toctree-l1"><a class="reference internal" href="Optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="Learning Rate Schedulers.html">Learning Rate Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="Trainer.html">Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="Vocabs.html">Vocabs</a></li>
<li class="toctree-l1"><a class="reference internal" href="Voice Activity Detection.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="Etc.html">Etc</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">KoSpeech</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Common Modules</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/Common Modules.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="common-modules">
<h1>Common Modules<a class="headerlink" href="#common-modules" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-kospeech.models.attention">
<span id="attention"></span><h2>Attention<a class="headerlink" href="#module-kospeech.models.attention" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="kospeech.models.attention.AdditiveAttention">
<em class="property">class </em><code class="descclassname">kospeech.models.attention.</code><code class="descname">AdditiveAttention</code><span class="sig-paren">(</span><em>d_model: int</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/attention.html#AdditiveAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.attention.AdditiveAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a additive attention (bahdanau) mechanism on the output features from the decoder.
Additive attention proposed in “Neural Machine Translation by Jointly Learning to Align and Translate” paper.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>d_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – dimension of model</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs: query, value</dt>
<dd><ul class="first last simple">
<li><strong>query</strong> (batch_size, q_len, hidden_dim): tensor containing the output features from the decoder.</li>
<li><strong>value</strong> (batch_size, v_len, hidden_dim): tensor containing features of the encoded input sequence.</li>
</ul>
</dd>
<dt>Returns: context, attn</dt>
<dd><ul class="first last simple">
<li><strong>context</strong>: tensor containing the context vector from attention mechanism.</li>
<li><strong>attn</strong>: tensor containing the alignment from the encoder outputs.</li>
</ul>
</dd>
<dt>Reference:</dt>
<dd><ul class="first last simple">
<li><strong>Neural Machine Translation by Jointly Learning to Align and Translate</strong>: <a class="reference external" href="https://arxiv.org/abs/1409.0473">https://arxiv.org/abs/1409.0473</a></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="kospeech.models.attention.AdditiveAttention.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>query: torch.Tensor</em>, <em>key: torch.Tensor</em>, <em>value: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/kospeech/models/attention.html#AdditiveAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.attention.AdditiveAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.attention.LocationAwareAttention">
<em class="property">class </em><code class="descclassname">kospeech.models.attention.</code><code class="descname">LocationAwareAttention</code><span class="sig-paren">(</span><em>d_model: int = 512</em>, <em>smoothing: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/attention.html#LocationAwareAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.attention.LocationAwareAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a location-aware attention mechanism on the output features from the decoder.
Location-aware attention proposed in “Attention-Based Models for Speech Recognition” paper.
The location-aware attention mechanism is performing well in speech recognition tasks.
We refer to implementation of ClovaCall Attention style.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>d_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – dimension of model</li>
<li><strong>smoothing</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – flag indication whether to use smoothing or not.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs: query, value, last_attn</dt>
<dd><ul class="first last simple">
<li><strong>query</strong> (batch, q_len, hidden_dim): tensor containing the output features from the decoder.</li>
<li><strong>value</strong> (batch, v_len, hidden_dim): tensor containing features of the encoded input sequence.</li>
<li><strong>last_attn</strong> (batch_size * num_heads, v_len): tensor containing previous timestep`s attention (alignment)</li>
</ul>
</dd>
<dt>Returns: output, attn</dt>
<dd><ul class="first last simple">
<li><strong>output</strong> (batch, output_len, dimensions): tensor containing the feature from encoder outputs</li>
<li><strong>attn</strong> (batch * num_heads, v_len): tensor containing the attention (alignment) from the encoder outputs.</li>
</ul>
</dd>
<dt>Reference:</dt>
<dd><ul class="first last simple">
<li><strong>Attention-Based Models for Speech Recognition</strong>: <a class="reference external" href="https://arxiv.org/abs/1506.07503">https://arxiv.org/abs/1506.07503</a></li>
<li><strong>ClovaCall</strong>: <a class="reference external" href="https://github.com/clovaai/ClovaCall/blob/master/las.pytorch/models/attention.py">https://github.com/clovaai/ClovaCall/blob/master/las.pytorch/models/attention.py</a></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="kospeech.models.attention.LocationAwareAttention.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>query: torch.Tensor</em>, <em>value: torch.Tensor</em>, <em>last_alignment_energy: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/kospeech/models/attention.html#LocationAwareAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.attention.LocationAwareAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.attention.MultiHeadAttention">
<em class="property">class </em><code class="descclassname">kospeech.models.attention.</code><code class="descname">MultiHeadAttention</code><span class="sig-paren">(</span><em>d_model: int = 512</em>, <em>num_heads: int = 8</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/attention.html#MultiHeadAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.attention.MultiHeadAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-Head Attention proposed in “Attention Is All You Need”
Instead of performing a single attention function with d_model-dimensional keys, values, and queries,
project the queries, keys and values h times with different, learned linear projections to d_head dimensions.
These are concatenated and once again projected, resulting in the final values.
Multi-head attention allows the model to jointly attend to information from different representation
subspaces at different positions.</p>
<dl class="docutils">
<dt>MultiHead(Q, K, V) = Concat(head_1, …, head_h) · W_o</dt>
<dd>where head_i = Attention(Q · W_q, K · W_k, V · W_v)</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>d_model</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The dimension of keys / values / quries (default: 512)</li>
<li><strong>num_heads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of attention heads. (default: 8)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs: query, key, value, mask</dt>
<dd><ul class="first last simple">
<li><strong>query</strong> (batch, q_len, d_model): tensor containing projection vector for decoder.</li>
<li><strong>key</strong> (batch, k_len, d_model): tensor containing projection vector for encoder.</li>
<li><strong>value</strong> (batch, v_len, d_model): tensor containing features of the encoded input sequence.</li>
<li><strong>mask</strong> (-): tensor containing indices to be masked</li>
</ul>
</dd>
<dt>Returns: output, attn</dt>
<dd><ul class="first last simple">
<li><strong>output</strong> (batch, output_len, dimensions): tensor containing the attended output features.</li>
<li><strong>attn</strong> (batch * num_heads, v_len): tensor containing the attention (alignment) from the encoder outputs.</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="kospeech.models.attention.MultiHeadAttention.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>query: torch.Tensor</em>, <em>key: torch.Tensor</em>, <em>value: torch.Tensor</em>, <em>mask: Optional[Any] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/kospeech/models/attention.html#MultiHeadAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.attention.MultiHeadAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.attention.ScaledDotProductAttention">
<em class="property">class </em><code class="descclassname">kospeech.models.attention.</code><code class="descname">ScaledDotProductAttention</code><span class="sig-paren">(</span><em>dim: int</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/attention.html#ScaledDotProductAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.attention.ScaledDotProductAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Scaled Dot-Product Attention proposed in “Attention Is All You Need”
Compute the dot products of the query with all keys, divide each by sqrt(dim),
and apply a softmax function to obtain the weights on the values</p>
<dl class="docutils">
<dt>Args: dim, mask</dt>
<dd>dim (int): dimension of attention
mask (torch.Tensor): tensor containing indices to be masked</dd>
<dt>Inputs: query, key, value, mask</dt>
<dd><ul class="first last simple">
<li><strong>query</strong> (batch, q_len, d_model): tensor containing projection vector for decoder.</li>
<li><strong>key</strong> (batch, k_len, d_model): tensor containing projection vector for encoder.</li>
<li><strong>value</strong> (batch, v_len, d_model): tensor containing features of the encoded input sequence.</li>
<li><strong>mask</strong> (-): tensor containing indices to be masked</li>
</ul>
</dd>
<dt>Returns: context, attn</dt>
<dd><ul class="first last simple">
<li><strong>context</strong>: tensor containing the context vector from attention mechanism.</li>
<li><strong>attn</strong>: tensor containing the attention (alignment) from the encoder outputs.</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="kospeech.models.attention.ScaledDotProductAttention.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>query: torch.Tensor</em>, <em>key: torch.Tensor</em>, <em>value: torch.Tensor</em>, <em>mask: Optional[Any] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/kospeech/models/attention.html#ScaledDotProductAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.attention.ScaledDotProductAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-kospeech.models.extractor">
<span id="extractor"></span><h2>Extractor<a class="headerlink" href="#module-kospeech.models.extractor" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="kospeech.models.extractor.CNNExtractor">
<em class="property">class </em><code class="descclassname">kospeech.models.extractor.</code><code class="descname">CNNExtractor</code><span class="sig-paren">(</span><em>activation: str = 'hardtanh'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/extractor.html#CNNExtractor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.extractor.CNNExtractor" title="Permalink to this definition">¶</a></dt>
<dd><p>Provides inteface of convolutional extractor.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Do not use this class directly, use one of the sub classes.</p>
</div>
<dl class="method">
<dt id="kospeech.models.extractor.CNNExtractor.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/extractor.html#CNNExtractor.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.extractor.CNNExtractor.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.extractor.DeepSpeech2Extractor">
<em class="property">class </em><code class="descclassname">kospeech.models.extractor.</code><code class="descname">DeepSpeech2Extractor</code><span class="sig-paren">(</span><em>activation: str = 'hardtanh'</em>, <em>mask_conv: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/extractor.html#DeepSpeech2Extractor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.extractor.DeepSpeech2Extractor" title="Permalink to this definition">¶</a></dt>
<dd><p>DeepSpeech2 extractor for automatic speech recognition described in
“Deep Speech 2: End-to-End Speech Recognition in English and Mandarin” paper
- <a class="reference external" href="https://arxiv.org/abs/1512.02595">https://arxiv.org/abs/1512.02595</a></p>
<dl class="method">
<dt id="kospeech.models.extractor.DeepSpeech2Extractor.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>inputs: torch.Tensor</em>, <em>input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Optional[Any]<a class="reference internal" href="_modules/kospeech/models/extractor.html#DeepSpeech2Extractor.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.extractor.DeepSpeech2Extractor.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.extractor.MaskConv">
<em class="property">class </em><code class="descclassname">kospeech.models.extractor.</code><code class="descname">MaskConv</code><span class="sig-paren">(</span><em>sequential: torch.nn.modules.container.Sequential</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/extractor.html#MaskConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.extractor.MaskConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Masking Convolutional Neural Network</p>
<p>Adds padding to the output of the module based on the given lengths.
This is to ensure that the results of the model do not change when batch sizes change during inference.
Input needs to be in the shape of (batch_size, channel, hidden_dim, seq_len)</p>
<p>Refer to <a class="reference external" href="https://github.com/SeanNaren/deepspeech.pytorch/blob/master/model.py">https://github.com/SeanNaren/deepspeech.pytorch/blob/master/model.py</a>
Copyright (c) 2017 Sean Naren
MIT License</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>sequential</strong> (<em>torch.nn</em>) – sequential list of convolution layer</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs: inputs, seq_lengths</dt>
<dd><ul class="first last simple">
<li><strong>inputs</strong> (torch.FloatTensor): The input of size BxCxHxT</li>
<li><strong>seq_lengths</strong> (torch.IntTensor): The actual length of each sequence in the batch</li>
</ul>
</dd>
<dt>Returns: output, seq_lengths</dt>
<dd><ul class="first last simple">
<li><strong>output</strong>: Masked output from the sequential</li>
<li><strong>seq_lengths</strong>: Sequence length of output from the sequential</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="kospeech.models.extractor.MaskConv.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>inputs: torch.Tensor</em>, <em>seq_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/kospeech/models/extractor.html#MaskConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.extractor.MaskConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="kospeech.models.extractor.MaskConv.get_sequence_lengths">
<code class="descname">get_sequence_lengths</code><span class="sig-paren">(</span><em>module: torch.nn.modules.module.Module</em>, <em>seq_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/kospeech/models/extractor.html#MaskConv.get_sequence_lengths"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.extractor.MaskConv.get_sequence_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate convolutional neural network receptive formula</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>module</strong> (<a class="reference external" href="https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmaster (1.8.0a0+2221ff5 ))"><em>torch.nn.Module</em></a>) – module of CNN</li>
<li><strong>seq_lengths</strong> (<em>torch.IntTensor</em>) – The actual length of each sequence in the batch</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Returns: seq_lengths</dt>
<dd><ul class="first last simple">
<li><strong>seq_lengths</strong>: Sequence length of output from the module</li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.extractor.VGGExtractor">
<em class="property">class </em><code class="descclassname">kospeech.models.extractor.</code><code class="descname">VGGExtractor</code><span class="sig-paren">(</span><em>activation: str</em>, <em>mask_conv: bool</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/extractor.html#VGGExtractor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.extractor.VGGExtractor" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG extractor for automatic speech recognition described in
“Advances in Joint CTC-Attention based End-to-End Speech Recognition with a Deep CNN Encoder and RNN-LM” paper
- <a class="reference external" href="https://arxiv.org/pdf/1706.02737.pdf">https://arxiv.org/pdf/1706.02737.pdf</a></p>
<dl class="method">
<dt id="kospeech.models.extractor.VGGExtractor.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>inputs: torch.Tensor</em>, <em>input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Optional[Any]<a class="reference internal" href="_modules/kospeech/models/extractor.html#VGGExtractor.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.extractor.VGGExtractor.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-kospeech.models.modules">
<span id="modules"></span><h2>Modules<a class="headerlink" href="#module-kospeech.models.modules" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="kospeech.models.modules.BNReluRNN">
<em class="property">class </em><code class="descclassname">kospeech.models.modules.</code><code class="descname">BNReluRNN</code><span class="sig-paren">(</span><em>input_size: int</em>, <em>hidden_dim: int = 512</em>, <em>rnn_type: str = 'gru'</em>, <em>bidirectional: bool = True</em>, <em>dropout_p: float = 0.1</em>, <em>device: str = 'cuda'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/modules.html#BNReluRNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.BNReluRNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Recurrent neural network with batch normalization layer &amp; ReLU activation function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – size of input</li>
<li><strong>hidden_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – the number of features in the hidden state <cite>h</cite></li>
<li><strong>rnn_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) – type of RNN cell (default: gru)</li>
<li><strong>bidirectional</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, becomes a bidirectional encoder (defulat: True)</li>
<li><strong>dropout_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) – dropout probability (default: 0.1)</li>
<li><strong>device</strong> (<em>torch.device</em>) – device - ‘cuda’ or ‘cpu’</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs: inputs</dt>
<dd><ul class="first last simple">
<li><strong>inputs</strong>: list of sequences, whose length is the batch size and within which each sequence is list of tokens</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="kospeech.models.modules.BNReluRNN.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>inputs: torch.Tensor</em>, <em>input_lengths: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/modules.html#BNReluRNN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.BNReluRNN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.modules.BaseRNN">
<em class="property">class </em><code class="descclassname">kospeech.models.modules.</code><code class="descname">BaseRNN</code><span class="sig-paren">(</span><em>input_size: int</em>, <em>hidden_dim: int = 512</em>, <em>num_layers: int = 1</em>, <em>rnn_type: str = 'lstm'</em>, <em>dropout_p: float = 0.3</em>, <em>bidirectional: bool = True</em>, <em>device: str = 'cuda'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/modules.html#BaseRNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.BaseRNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a multi-layer RNN to an input sequence.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Do not use this class directly, use one of the sub classes.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – size of input</li>
<li><strong>hidden_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – dimension of RNN`s hidden state vector</li>
<li><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – number of RNN layers (default: 1)</li>
<li><strong>bidirectional</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, becomes a bidirectional RNN (defulat: False)</li>
<li><strong>rnn_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) – type of RNN cell (default: gru)</li>
<li><strong>dropout_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) – dropout probability (default: 0)</li>
<li><strong>device</strong> (<em>torch.device</em>) – device - ‘cuda’ or ‘cpu’</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><p class="first last"><strong>= Dictionary of supported rnns</strong> (<em>supported_rnns</em>) – </p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="kospeech.models.modules.BaseRNN.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/modules.html#BaseRNN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.BaseRNN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.modules.LayerNorm">
<em class="property">class </em><code class="descclassname">kospeech.models.modules.</code><code class="descname">LayerNorm</code><span class="sig-paren">(</span><em>dim: int</em>, <em>eps: float = 1e-06</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/modules.html#LayerNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.LayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper class of torch.nn.LayerNorm</p>
<dl class="method">
<dt id="kospeech.models.modules.LayerNorm.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>z: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/kospeech/models/modules.html#LayerNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.LayerNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.modules.Linear">
<em class="property">class </em><code class="descclassname">kospeech.models.modules.</code><code class="descname">Linear</code><span class="sig-paren">(</span><em>in_features: int</em>, <em>out_features: int</em>, <em>bias: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/modules.html#Linear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.Linear" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper class of torch.nn.Linear
Weight initialize by xavier initialization and bias initialize to zeros.</p>
<dl class="method">
<dt id="kospeech.models.modules.Linear.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="_modules/kospeech/models/modules.html#Linear.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.Linear.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="kospeech.models.modules.View">
<em class="property">class </em><code class="descclassname">kospeech.models.modules.</code><code class="descname">View</code><span class="sig-paren">(</span><em>shape: tuple</em>, <em>contiguous: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/modules.html#View"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.View" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper class of torch.view() for Sequential module.</p>
<dl class="method">
<dt id="kospeech.models.modules.View.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>inputs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/kospeech/models/modules.html#View.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#kospeech.models.modules.View.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Checkpoint.html" class="btn btn-neutral float-right" title="Checkpoint" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Speech Transformer.html" class="btn btn-neutral float-left" title="Speech Transformer" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Soohwan Kim

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>